{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb61fe84-8a17-44bf-a107-41ef6e703295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9a7a9cb-13ea-424b-a3c6-d2e58f491743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "data_dir = \"data\"  # Directory containing text files\n",
    "file_paths = [os.path.join(data_dir, filename) for filename in os.listdir(data_dir)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceecf1b4-d178-444e-bda5-e45c17d78073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/15.txt',\n",
       " 'data/14.txt',\n",
       " 'data/16.txt',\n",
       " 'data/17.txt',\n",
       " 'data/13.txt',\n",
       " 'data/12.txt',\n",
       " 'data/10.txt',\n",
       " 'data/11.txt',\n",
       " 'data/9.txt',\n",
       " 'data/8.txt',\n",
       " 'data/5.txt',\n",
       " 'data/4.txt',\n",
       " 'data/6.txt',\n",
       " 'data/7.txt',\n",
       " 'data/3.txt',\n",
       " 'data/2.txt',\n",
       " 'data/1.txt',\n",
       " 'data/.ipynb_checkpoints',\n",
       " 'data/20.txt',\n",
       " 'data/19.txt',\n",
       " 'data/18.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "888b7538-6638-492b-a48f-400f74c4a262",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths.remove('data/.ipynb_checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35dba90e-6014-4a9c-8502-85ad44b3603a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/15.txt',\n",
       " 'data/14.txt',\n",
       " 'data/16.txt',\n",
       " 'data/17.txt',\n",
       " 'data/13.txt',\n",
       " 'data/12.txt',\n",
       " 'data/10.txt',\n",
       " 'data/11.txt',\n",
       " 'data/9.txt',\n",
       " 'data/8.txt',\n",
       " 'data/5.txt',\n",
       " 'data/4.txt',\n",
       " 'data/6.txt',\n",
       " 'data/7.txt',\n",
       " 'data/3.txt',\n",
       " 'data/2.txt',\n",
       " 'data/1.txt',\n",
       " 'data/20.txt',\n",
       " 'data/19.txt',\n",
       " 'data/18.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9e5689c-1ea9-4f68-9fdb-99b680d09f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = []\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text = file.read()\n",
    "        texts.append(text)\n",
    "\n",
    "corpus = \" \".join(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "590d9313-e39c-43a5-badc-7051dffb66f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122896"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( corpus ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d14fa69d-e6d0-4421-8e08-65f160606d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization and Vocabulary Creation (you can use any tokenization library such as spaCy or NLTK)\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts([corpus])\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences([corpus])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aad4f1ad-be1f-404a-aab6-cd8620aebeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training sequences\n",
    "seq_length = 100\n",
    "sequences = [sequences[i:i+seq_length] for i in range(0, len(sequences) - seq_length, seq_length)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "502bfde8-a1ad-4d45-bdcc-8156fffd9197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture Design\n",
    "embedding_dim = 128\n",
    "\n",
    "inputs = Input(shape=(seq_length,))\n",
    "embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(inputs)\n",
    "\n",
    "outputs = Dense(vocab_size, activation='softmax')(embedding_layer)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=Adam(), loss=SparseCategoricalCrossentropy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "038b48b6-d2c6-43d1-9e8f-f3ebb32f545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "import numpy as np\n",
    "# Generate training sequences\n",
    "seq_length = 100\n",
    "stride = 1  # Adjust stride to shift the input and target sequences by one token\n",
    "sequences = [sequences[i:i+seq_length] for i in range(0, len(sequences) - seq_length, stride)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed54f7b7-092f-4866-bb97-54f26af87778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data\n",
    "train_inputs = np.array([sequence[:-1] for sequence in sequences])\n",
    "train_targets = np.array([sequence[1:] for sequence in sequences])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8fd4dcd-5822-4125-8bb5-8c253e5ab18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"functional_3\" is incompatible with the layer: expected shape=(None, 100), found shape=(None, 99, 100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_targets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Professional/Jio-2024/WarmHole/ops_env/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Professional/Jio-2024/WarmHole/ops_env/lib/python3.11/site-packages/keras/src/layers/input_spec.py:245\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m spec_dim \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[0;32m--> 245\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    246\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of layer \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible with the layer: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpected shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mspec\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    249\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    250\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 of layer \"functional_3\" is incompatible with the layer: expected shape=(None, 100), found shape=(None, 99, 100)"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model.fit(train_inputs, train_targets, epochs=10, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9876a04e-4a04-4b0f-9acc-7e09aa5da0e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ops_env",
   "language": "python",
   "name": "ops_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
